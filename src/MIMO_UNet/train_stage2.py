# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# NVIDIA CORPORATION and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA CORPORATION is strictly prohibited.


import torch
import random
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import sys
import tqdm  # type: ignore
import cv2
import os
import argparse
import logging
import numpy as np
from torch.utils.data.distributed import DistributedSampler
import torch.distributed as dist
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(parent_dir)
from dataloader import Multi_GoPro_Loader, RealBlur_Loader  # type: ignore
from MIMO_UNet.models.LatentEncoder import LE_arch  # type: ignore
from MIMO_UNet.models.LatentAngleDM import LatentAngleDiffusion  # type: ignore
from MIMO_UNet.models.losses import CharbonnierLoss, VGGPerceptualLoss, L1andPerceptualLoss  # type: ignore
from utils.utils import calc_psnr, same_seed, count_parameters, tensor2cv, AverageMeter, judge_and_remove_module_dict  # type: ignore
import torch.nn.functional as F
import pyiqa  # type: ignore
from tensorboardX import SummaryWriter  # type: ignore

cv2.setNumThreads(0)
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = True

def rfft(x: torch.Tensor, d: int) -> torch.Tensor:
    """FFT function compatible with both old and new PyTorch versions."""
    t = torch.fft.fft(x, dim=(-d))
    r = torch.stack((t.real, t.imag), -1)
    return r

class Trainer():
    def __init__(self, dataloader_train, dataloader_val, model_le, model_dm, optimizer, scheduler, args, writer) -> None:
        self.dataloader_train = dataloader_train
        self.dataloader_val = dataloader_val
        self.model_le = model_le
        self.model_dm = model_dm
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.args = args
        self.writer = writer
        self.epoch = 0
        self.device = self.args.device
        self.grad_clip = 1

        self.scheduler.T_max = self.args.end_epoch
        if args.criterion == "l1":
            self.criterion = CharbonnierLoss()
        elif args.criterion == "perceptual":
            self.criterion = VGGPerceptualLoss().to(device)
        elif args.criterion == "l1perceptual":
             self.criterion = L1andPerceptualLoss(gamma=args.gamma).to(device)
        else:
            raise ValueError(f"criterion not supported {args.criterion}")
        
    def train(self):
        if dist.get_rank() == 0:
            print('###########################################')
            print('Start_Epoch:', self.args.start_epoch)
            print('End_Epoch:', self.args.end_epoch)
            print('Model:', self.args.model_name)
            print(f"Optimizer:{self.optimizer.__class__.__name__}")
            print(f"Scheduler:{self.scheduler.__class__.__name__ if self.scheduler else None}")
            print(f"Train Data length:{len(dataloader_train.dataset)}")	# type: ignore[arg-type]
            print("start train !!")
            print('###########################################')

        for epoch in range(args.start_epoch, args.end_epoch + 1):
            self.epoch = epoch
            self._train_epoch()

            if dist.get_rank() == 0:
                if (epoch % self.args.validation_epoch) == 0 or epoch == self.args.end_epoch:
                    self.valid()

                if(self.args.val_save_epochs > 0 and epoch % self.args.val_save_epochs == 0 or epoch == self.args.end_epoch):
                    self.val_save_image(dir_path=self.args.dir_path, dataset=self.dataloader_val.dataset)

                self.save_model()
    
    def _train_epoch(self):
        train_sampler.set_epoch(self.epoch)
        tq = tqdm.tqdm(self.dataloader_train, total=len(self.dataloader_train))
        tq.set_description(f'Epoch [{self.epoch}/{self.args.end_epoch}] training')
        total_train_loss = AverageMeter()
        total_train_psnr = AverageMeter()
        total_train_lpips = AverageMeter()
        
        for idx, sample in enumerate(tq):
            self.model_le.eval()
            self.model_dm.train()
            self.optimizer.zero_grad()
             # input: [B, C, H, W], gt: [B, C, H, W]
            blur, sharp = sample['blur'].to(device), sample['sharp'].to(device)
            z_gt = self.model_le(blur, sharp)
            z_pred = self.model_dm(blur)

            loss_prior = self.criterion(z_pred, z_gt)

            loss = loss_prior
            loss.backward()

            #torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)

            self.optimizer.step()

            total_train_loss.update(loss.detach().item())
            # psnr = calc_psnr(outputs[2].detach(), sharp.detach())
            # total_train_psnr.update(psnr)

            tq.set_postfix({'loss': total_train_loss.avg,'lr': optimizer.param_groups[0]['lr']})

        if self.scheduler:
            self.scheduler.step()
        if self.writer and dist.get_rank() == 0:
            self.writer.add_scalar('Loss/Train_loss', total_train_loss.avg, self.epoch)
            # self.writer.add_scalar('Loss/Train_psnr', total_train_psnr.avg, self.epoch)
            # self.writer.add_scalar('Loss/Train_lpips', total_train_lpips.avg, self.epoch)
            logging.info(
                f'Epoch [{self.epoch}/{args.end_epoch}]: Train_loss: {total_train_loss.avg:.4f}')
    
    @torch.no_grad()
    def _valid(self, blur, sharp):
        self.model_le.eval()
        self.model_dm.eval()
        z_gt = self.model_le(blur, sharp)
        z_pred = self.model_dm(blur)

        loss_prior = self.criterion(z_pred, z_gt)

        loss = loss_prior
        # psnr = torch.mean(self.psnr_func(outputs[2].detach()+0.5, sharp.detach()+0.5)).item()
        # lpips = torch.mean(self.lpips_func(outputs[2].detach()+0.5, sharp.detach()+0.5)).item()
        return 0, 0, loss.item()
    
    @torch.no_grad()
    def valid(self):
        self.model_le.eval()
        self.model_dm.eval()
      
        total_val_loss = AverageMeter()
        tq = tqdm.tqdm(self.dataloader_val, total=len(self.dataloader_val))
        tq.set_description(f'Epoch [{self.epoch}/{self.args.end_epoch}] Validation')
        for idx, sample in enumerate(tq):
            blur, sharp = sample['blur'].to(device), sample['sharp'].to(device)
            psnr, lpips, loss = self._valid(blur, sharp)
            # total_val_psnr.update(psnr)
            # total_val_lpips.update(lpips)
            total_val_loss.update(loss)
            tq.set_postfix(Loss=total_val_loss.avg)

        # self.writer.add_scalar('Val/Test_lpips', total_val_lpips.avg, self.epoch)
        # self.writer.add_scalar('Val/Test_psnr', total_val_psnr.avg, self.epoch)
        self.writer.add_scalar('Val/Test_loss', total_val_loss.avg, self.epoch)
        logging.info(
            f'Crop Validation Epoch [{self.epoch}/{args.end_epoch}]: Test Loss: {total_val_loss.avg:.4f} ')

        best_state = {'model_dm_state': self.model_dm.module.state_dict(), 'args': args}
        torch.save(best_state, os.path.join(args.dir_path, 'last_dm_{}.pth'.format(args.model_name)))

        # if self.best_psnr < total_val_psnr.avg:
        #     self.best_psnr = total_val_psnr.avg
        #     args.best_psnr = self.best_psnr
        #     best_state = {'model_state': self.model.module.state_dict(), 'args': args}
        #     torch.save(best_state, os.path.join(args.dir_path, 'best_deblur_{}.pth'.format(args.model_name)))

        #     best_state = {'model_dm_state': self.model_dm.module.state_dict(), 'args': args}
        #     torch.save(best_state, os.path.join(args.dir_path, 'best_dm_{}.pth'.format(args.model_name)))

        #     print('Saving model with best PSNR {:.3f}...'.format(self.best_psnr))
        #     logging.info('Saving model with best PSNR {:.3f}...'.format(self.best_psnr))
            
    def save_model(self):
        """save model parameters"""
        training_state = {'epoch': self.epoch, 
                          'model_dm_state': self.model_dm.module.state_dict(),
                          'optimizer_state': self.optimizer.state_dict(),
                          'scheduler_state': self.scheduler.state_dict() if self.scheduler else None,
                          'args': args}
        torch.save(training_state, os.path.join(self.args.dir_path, 'last_{}.pth'.format(self.args.model_name)))

        if (self.epoch % self.args.check_point_epoch) == 0:
            torch.save(training_state, os.path.join(self.args.dir_path, 'epoch_{}_{}.pth'.format(self.epoch, self.args.model_name)))

        if self.epoch == self.args.end_epoch:
            model_state = {'model_dm_state': self.model_dm.module.state_dict(), 'args': args}
            torch.save(model_state, os.path.join(args.dir_path, 'final_dm_{}.pth'.format(args.model_name)))

    @torch.no_grad()
    def val_save_image(self, dir_path, dataset, val_num=3):
        """use train set to val and save image"""
        os.makedirs(dir_path, exist_ok=True)
        self.model_dm.eval()
        for idx in random.sample(range(0, len(dataset)), val_num):
            sample = dataset[idx]
            blur, sharp = sample['blur'].unsqueeze(0).to(device), sample['sharp'].unsqueeze(0).to(device)
            b, c, h, w = blur.shape
            factor = 8
            h_n = (factor - h % factor) % factor
            w_n = (factor - w % factor) % factor
            blur = torch.nn.functional.pad(blur, (0, w_n, 0, h_n), mode='reflect')
            # sharp_in = torch.nn.functional.pad(sharp, (0, w_n, 0, h_n), mode='reflect')
            z_pred = self.model_dm(blur)

if __name__ == "__main__":
    # hyperparameters
    parser = argparse.ArgumentParser()
    parser.add_argument("--end_epoch", default=3000, type=int)
    parser.add_argument("--start_epoch", default=1, type=int)
    parser.add_argument("--batch_size", default=20, type=int)
    parser.add_argument("--crop_size", default=256, type=int)
    parser.add_argument("--validation_epoch", default=25, type=int)
    parser.add_argument("--check_point_epoch", default=100, type=int)
    parser.add_argument("--init_lr", default=1e-4, type=float)
    parser.add_argument("--min_lr", default=1e-6, type=float)
    parser.add_argument("--gamma", default=0.5, type=float)
    parser.add_argument("--optimizer", default='adam', type=str)
    parser.add_argument("--criterion", default='l1', type=str)
    parser.add_argument("--data_path", default='./dataset/GOPRO_Large', type= str)
    parser.add_argument("--dir_path", default='./experiments/MIMO_UNet/GoPro/stage2', type=str)
    parser.add_argument("--model_name", default='AngleDM', type=str)
    parser.add_argument("--model", default='AngleDM', type=str)
    parser.add_argument("--model_le_path", default=None, type=str)
    parser.add_argument("--seed", default=2023, type=int)
    parser.add_argument("--val_save_epochs", default=100, type=int)
    parser.add_argument("--resume", default=None, type=str)
    parser.add_argument("--only_use_generate_data", action='store_true', help="only use generated data to train model.")
    parser.add_argument("--local_rank", default=os.getenv('LOCAL_RANK', -1), type=int)
    parser.add_argument("--total_timestamps", default=5, type=int)
    parser.add_argument("--in_channels", default=1, type=int)
    parser.add_argument("--pixel_unshuffle_factor", default=4, type=int)
    parser.add_argument("--phi_max", default=180.0, type=float)
    parser.add_argument("--phi_min", default=60.0, type=float)
    parser.add_argument(
        "--focus_table_path",
        default="../code_diffusion/cold_diffuson/linear_indices_100.focus_table.npz",
        type=str,
    )
    
    args = parser.parse_args()

    if args.local_rank != -1:
        torch.cuda.set_device(args.local_rank)
        device = torch.device("cuda", args.local_rank)
        dist.init_process_group(backend="nccl", init_method='env://')

    net_le = LE_arch(
        bn=True,
        in_channels=args.in_channels,
        pixel_unshuffle_factor=args.pixel_unshuffle_factor,
    )
    net_dm = LatentAngleDiffusion(
        total_timestamps=args.total_timestamps,
        phi_max=args.phi_max,
        phi_min=args.phi_min,
        focus_table_path=args.focus_table_path,
        in_channels=args.in_channels,
        pixel_unshuffle_factor=args.pixel_unshuffle_factor,
    )

    load_le_model_state = torch.load(args.model_le_path)

    load_le_model_state["model_le_state"] = judge_and_remove_module_dict(load_le_model_state["model_le_state"])
    net_le.load_state_dict(load_le_model_state["model_le_state"])

    # training seed
    seed = args.seed + args.local_rank
    torch.backends.cudnn.enabled = True
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = True
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.cuda.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

    args.device = device
    print("device:", device)
    num_gpus = torch.cuda.device_count()
    net_le.to(device)
    net_dm.to(device)

    print(args.__dict__.items())

    optim_params = []

    for k, v in net_dm.named_parameters():
        if v.requires_grad:
            optim_params.append(v)

    if args.optimizer == "adam":
        optimizer = optim.Adam([{'params': optim_params}], lr=args.init_lr)
    elif args.optimizer == "adamw":
        optimizer = optim.AdamW([{'params': optim_params}], lr=args.init_lr, weight_decay=1e-4)
    else:
        raise ValueError(f"optimizer not supported {args.optimizer}")

    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.end_epoch, eta_min=args.min_lr)
    # load pretrained
    # configure map_location properly
    map_location = {'cuda:%d' % 0: 'cuda:%d' % args.local_rank}
    if os.path.exists(os.path.join(args.dir_path, 'last_{}.pth'.format(args.model_name))):
        print('load_pretrained')
        training_state = (torch.load(os.path.join(args.dir_path, 'last_{}.pth'.format(args.model_name)), map_location=map_location))
        args.start_epoch = training_state['epoch'] + 1
        if 'best_psnr' in training_state['args']:
            args.best_psnr = training_state['args'].best_psnr

        new_weight = net_dm.state_dict()
        training_state["model_dm_state"] = judge_and_remove_module_dict(training_state["model_dm_state"])
        new_weight.update(training_state['model_dm_state'])
        net_dm.load_state_dict(new_weight)

        new_optimizer = optimizer.state_dict()
        new_optimizer.update(training_state['optimizer_state'])
        optimizer.load_state_dict(new_optimizer)
        new_scheduler = scheduler.state_dict()
        new_scheduler.update(training_state['scheduler_state'])
        scheduler.load_state_dict(new_scheduler)
    elif args.resume:
        print('load_resume_pretrained')
        model_load = torch.load(args.resume, map_location=map_location)
        model_load["model_dm_state"] = judge_and_remove_module_dict(model_load["model_dm_state"])
        net_dm.load_state_dict(model_load['model_dm_state'])
        # else:
        #     model_load = judge_and_remove_module_dict(model_load)
        #     net.load_state_dict(model_load)
        os.makedirs(args.dir_path, exist_ok=True)
    else:
        os.makedirs(args.dir_path, exist_ok=True)
    
    # Model
    net_le = nn.parallel.DistributedDataParallel(net_le, device_ids=[args.local_rank],
                                          output_device=args.local_rank)

    net_dm = nn.parallel.DistributedDataParallel(net_dm, device_ids=[args.local_rank],
                                          output_device=args.local_rank)
    # Traning loader
    dataset_name = args.data_path.split('/')[-1]
    train_data_path = args.data_path

    if dataset_name == "GOPRO_Large":
        Train_set = Multi_GoPro_Loader(data_path=train_data_path, mode="train", crop_size=args.crop_size)
    elif (dataset_name == "Realblur_J") or (dataset_name == "Realblur_R"):
        Train_set = RealBlur_Loader(data_path=train_data_path, mode="train", crop_size=args.crop_size, ZeroToOne=False)
    
    train_sampler: DistributedSampler[tuple[torch.Tensor, ...]] = DistributedSampler(Train_set)
    dataloader_train = DataLoader(Train_set, sampler=train_sampler, batch_size=args.batch_size//num_gpus, num_workers=8, pin_memory=True)

    # Val loader
    if dataset_name == "GOPRO_Large":
        Val_set = Multi_GoPro_Loader(data_path=args.data_path, mode="test", crop_size=args.crop_size)
    elif (dataset_name == "Realblur_J") or (dataset_name == "Realblur_R"):
        Val_set = RealBlur_Loader(data_path=train_data_path, mode="test", crop_size=args.crop_size, ZeroToOne=False)

    dataloader_val = DataLoader(Val_set, batch_size=args.batch_size//num_gpus, shuffle=True, num_workers=8,
                                drop_last=False, pin_memory=True)
    writer = None
    if dist.get_rank() == 0:

        logging.basicConfig(
            filename=os.path.join(args.dir_path, 'train.log') , format='%(levelname)s:%(message)s', encoding='utf-8', level=logging.INFO)
        
        logging.info(f'args: {args}')
        logging.info(f'latent encoder: {net_le}')
        logging.info(f'latent dm encoder: {net_dm}')
        logging.info(f'latent encoder parameters: {count_parameters(net_le)}')
        logging.info(f'latent dm encoder parameters: {count_parameters(net_dm)}')
        logging.info(f"Optimizer:{optimizer.__class__.__name__}")
        logging.info(f"Train Data length:{len(dataloader_train.dataset)}")  # type: ignore[arg-type]

        writer = SummaryWriter(os.path.join("MIMO_log", args.model_name))
        writer.add_text("args", str(args))

    trainer = Trainer(dataloader_train, dataloader_val, net_le, net_dm,optimizer, scheduler, args, writer)
    trainer.train()
    

    
